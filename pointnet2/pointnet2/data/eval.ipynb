{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (\n",
    "    division,\n",
    "    absolute_import,\n",
    "    with_statement,\n",
    "    print_function,\n",
    "    unicode_literals,\n",
    ")\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "\n",
    "def _get_data_files(list_filename):\n",
    "    with open(list_filename) as f:\n",
    "        return [line.rstrip()[5:] for line in f]\n",
    "\n",
    "\n",
    "def _load_data_file(name):\n",
    "    f = h5py.File(name)\n",
    "    data = f[\"data\"][:]\n",
    "    label = f[\"label\"][:]\n",
    "    return data, label\n",
    "\n",
    "\n",
    "class ModelNet40Cls(data.Dataset):\n",
    "    def __init__(self, num_points, transforms=None, train=True, download=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.folder = \"modelnet40_ply_hdf5_2048\"\n",
    "        self.data_dir = os.path.join(BASE_DIR, self.folder)\n",
    "        self.url = \"https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\"\n",
    "\n",
    "        if download and not os.path.exists(self.data_dir):\n",
    "            zipfile = os.path.join(BASE_DIR, os.path.basename(self.url))\n",
    "            subprocess.check_call(\n",
    "                shlex.split(\"curl {} -o {}\".format(self.url, zipfile))\n",
    "            )\n",
    "\n",
    "            subprocess.check_call(\n",
    "                shlex.split(\"unzip {} -d {}\".format(zipfile, BASE_DIR))\n",
    "            )\n",
    "\n",
    "            subprocess.check_call(shlex.split(\"rm {}\".format(zipfile)))\n",
    "\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.files = _get_data_files(os.path.join(self.data_dir, \"train_files.txt\"))\n",
    "        else:\n",
    "            self.files = _get_data_files(os.path.join(self.data_dir, \"test_files.txt\"))\n",
    "\n",
    "        point_list, label_list = [], []\n",
    "        for f in self.files:\n",
    "            points, labels = _load_data_file(os.path.join(BASE_DIR, f))\n",
    "            point_list.append(points)\n",
    "            label_list.append(labels)\n",
    "\n",
    "        self.points = np.concatenate(point_list, 0)\n",
    "        self.labels = np.concatenate(label_list, 0)\n",
    "        self.set_num_points(num_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pt_idxs = np.arange(0, self.num_points)\n",
    "        np.random.shuffle(pt_idxs)\n",
    "\n",
    "        current_points = self.points[idx, pt_idxs].copy()\n",
    "        label = torch.from_numpy(self.labels[idx]).type(torch.LongTensor)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            current_points = self.transforms(current_points)\n",
    "\n",
    "        return current_points, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def set_num_points(self, pts):\n",
    "        self.num_points = min(self.points.shape[1], pts)\n",
    "\n",
    "    def randomize(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/shengyu/anaconda/envs/venv_pointnet/lib/python3.7/site-packages/ipykernel_launcher.py:25: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import data_utils as d_utils\n",
    "import numpy as np\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "        d_utils.PointcloudToTensor(),\n",
    "        d_utils.PointcloudRotate(axis=np.array([1, 0, 0])),\n",
    "        d_utils.PointcloudScale(),\n",
    "        d_utils.PointcloudTranslate(),\n",
    "        d_utils.PointcloudJitter(),\n",
    "    ])\n",
    "dset = ModelNet40Cls(16, train=True, transforms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 2048, 3) (9840, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dset.points.shape,dset.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> 9840 samples in total, each sample has 2048 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004929"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dset.points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.88815236"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dset.points[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScanNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from pointnet2.models import Pointnet2ClsMSG as Pointnet\n",
    "from pointnet2.models.pointnet2_msg_cls import model_fn_decorator\n",
    "import pointnet2.data.data_utils as d_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        d_utils.PointcloudToTensor(),\n",
    "        d_utils.PointcloudScale(),\n",
    "        d_utils.PointcloudRotate(),\n",
    "        d_utils.PointcloudRotatePerturbation(),\n",
    "        d_utils.PointcloudTranslate(),\n",
    "        d_utils.PointcloudJitter(),\n",
    "        d_utils.PointcloudRandomInputDropout(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, glob, math, torch.utils.data, scipy.ndimage, multiprocessing as mp\n",
    "import os\n",
    "import plyfile\n",
    "\n",
    "def get_scene_type_id(type_name, type_mapping):\n",
    "    name = type_name.strip().lower()\n",
    "    name=name.replace(' ','')\n",
    "    if name in type_mapping:\n",
    "        return type_mapping[name]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_field_from_info_file(filename, field_name):\n",
    "    lines = open(filename).read().splitlines()\n",
    "    lines = [line.split(' = ') for line in lines]\n",
    "    mapping = { x[0]:x[1] for x in lines }\n",
    "    if field_name in mapping:\n",
    "        return mapping[field_name]\n",
    "    else:\n",
    "        logger.info('Failed to find %s in info file %s' % (field_name, filename))\n",
    "\n",
    "# input: scene_types.txt or scene_types_all.txt\n",
    "def read_scene_types_mapping(filename, remove_spaces=True):\n",
    "    assert os.path.isfile(filename)\n",
    "    mapping = dict()\n",
    "    lines = open(filename).read().splitlines()\n",
    "    lines = [line.split('\\t') for line in lines]\n",
    "    if remove_spaces:\n",
    "        mapping = { x[1].strip().replace(' ',''):int(x[0]) for x in lines }\n",
    "    else:\n",
    "        mapping = { x[1]:int(x[0]) for x in lines }        \n",
    "    return mapping\n",
    "\n",
    "\n",
    "\n",
    "# get the list of files\n",
    "def get_files(base_dir):\n",
    "    path_data=sorted(glob.glob(base_dir+'/*/sparse.ply'))   # only use xyz and raw RGB\n",
    "    path_label=sorted(glob.glob(base_dir+'/*/*.txt'))  # we can access the scene type from here\n",
    "    return path_data,path_label\n",
    "\n",
    "class ScanNet(torch.utils.data.Dataset):\n",
    "    def __init__(self,base_dir,transforms):\n",
    "        torch.utils.data.Dataset.__init__(self)\n",
    "        point_list,label_list=[],[]\n",
    "        \n",
    "        # get scene class\n",
    "        path_scene_types_all='/net/pf-pc27/scratch3/scannet/tasks/scene_types_all.txt'\n",
    "        self.scene_type_mapping = read_scene_types_mapping(path_scene_types_all, remove_spaces=True)\n",
    "        \n",
    "        # load data, here we only take xyz\n",
    "        path_data,path_label=get_files(base_dir)\n",
    "        assert len(path_data)==len(path_label)\n",
    "        for i in range(len(path_data)):\n",
    "            # get label\n",
    "            path_info_file=path_label[i]\n",
    "            scene_name = os.path.splitext(os.path.basename(path_info_file))[0]\n",
    "            type_name = get_field_from_info_file(path_info_file, 'sceneType')\n",
    "            type_id = get_scene_type_id(type_name, self.scene_type_mapping)\n",
    "            label=type_id-1\n",
    "            \n",
    "            # get data\n",
    "            path_points=path_data[i]\n",
    "            a=plyfile.PlyData().read(path_points)\n",
    "            v=np.array([list(x) for x in a.elements[0]])\n",
    "            pts=v[:,:3]\n",
    "            pts-=pts.mean(0) # center the coordinates\n",
    "            pts/=4   # scale the coordinates\n",
    "            point_list.append(np.expand_dims(pts,0))\n",
    "            label_list.append(label)\n",
    "        \n",
    "        self.points=np.concatenate(point_list,0)\n",
    "        print(self.points.shape)\n",
    "        self.labels=np.expand_dims(np.array(label_list),1)\n",
    "        print(self.labels.shape)\n",
    "        self.transforms=transforms\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        current_points = self.points[idx].copy()\n",
    "        label = torch.from_numpy(self.labels[idx]).type(torch.LongTensor)\n",
    "        if self.transforms is not None:\n",
    "            current_points = self.transforms(current_points)\n",
    "\n",
    "        return current_points, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 4096, 3)\n",
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "base_train='/net/pf-pc27/scratch3/scannet/train'\n",
    "base_val='/net/pf-pc27/scratch3/scannet/val'\n",
    "\n",
    "test_set = ScanNet(base_val, transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts=test_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77187437, 0.89486996, 0.44139409])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_set.points[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86286551, -0.92208023, -0.11601438])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(test_set.points[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_loader=iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=next(iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts=batch[0][0]\n",
    "label=batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.7703, 0.5847, 0.7663]),\n",
       "indices=tensor([  41, 1219, 3284]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([-0.4514, -0.6611, -0.8184]),\n",
       "indices=tensor([3300,    2, 3997]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pointnet",
   "language": "python",
   "name": "venv_pointnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
